In recent years, \acp{LLM} have made significant progress in solving a variety of reasoning and problem-solving tasks without the need for fine-tuning~\cite{radfordLanguageModelsAre2019}. These advancements enable the models to perform well in areas such as mathematical reasoning, logical inference, and commonsense understanding~\cite{panLogicLMEmpoweringLarge2023, qiaoReasoningLanguageModel2023, naveedComprehensiveOverviewLarge2024}. Techniques like \ac{ICL}~\cite{brownLanguageModelsAre2020}, i.e., learning from a few examples in the model's prompt, and \ac{CoT} prompting~\cite{weiChainofThoughtPromptingElicits2023}, which enhances reasoning through step-by-step explanations, have further boosted their ability to tackle complex tasks by enabling greater generalization through prompt optimization~\cite{brownLanguageModelsAre2020,weiChainofThoughtPromptingElicits2023}. However, most research on these advancements primarily focuses on vertical thinking, a problem-solving approach that follows a structured logical step-by-step process, where each step logically builds upon the previous one~\cite{jiangBRAINTEASERLateralThinking2023}.

An alternative to vertical thinking is lateral thinking, which takes a creative and unconventional approach to problem-solving. Instead of following a strictly logical progression, lateral thinking encourages breaking away from traditional reasoning patterns and exploring alternative interpretations~\cite{jiangBRAINTEASERLateralThinking2023, jiangSemEval2024Task92024}. This method is particularly useful for solving problems that require insight, flexibility, and out-of-the-box thinking.

While numerous datasets exist for commonsense reasoning and structured problem-solving, lateral thinking tasks have received significantly less attention~\cite{jiangBRAINTEASERLateralThinking2023, jiangSemEval2024Task92024}. Most research has focused on enhancing logical reasoning, while lateral thinking problems are often overlooked and considered less relevant~\cite{jiangBRAINTEASERLateralThinking2023, jiangSemEval2024Task92024}. As a result, the ability of \acp{LLM} to tackle lateral thinking tasks remains largely unexplored.

To address this gap, \textcite{jiangBRAINTEASERLateralThinking2023} introduced \citetitle{jiangBRAINTEASERLateralThinking2023}, a benchmark designed to evaluate lateral thinking abilities. This benchmark features problems that challenge common sense and require unconventional reasoning, diverging from typical reasoning patterns. At SemEval 2024 Task 9~\cite{jiangSemEval2024Task92024}, \citetitle{jiangBRAINTEASERLateralThinking2023} was expanded into a competition format, where participants explored various methods, including fine-tuning, \ac{ICL}, and other prompting techniques, such as \ac{CoT}, to enhance model performance in lateral reasoning tasks.

An important finding from the competition was that most participants (90\%) relied on closed-source \acp{LLM}~\cite{jiangSemEval2024Task92024}, such as OpenAI's \acs{GPT}-4~\cite{openaiGPT4TechnicalReport2024}, \acs{GPT}-3.5, and Gemini Pro~\cite{teamGeminiFamilyHighly2024}. In contrast, newer \acp{oLLM}, such as \ac{LLaMA} 3~\cite{grattafioriLlama3Herd2024}, \ac{Gemma}~\cite{teamGemma2Improving2024}, and \ac{Qwen}~\cite{qwenQwen25TechnicalReport2025}, were not evaluated. Given the recent advancements in reasoning demonstrated by such open models, further exploration of their capabilities in lateral thinking is warranted~\cite{OpenLLMLeaderboard, grattafioriLlama3Herd2024, teamGemma2Improving2024, qwenQwen25TechnicalReport2025}.

This paper investigates the performance of \acp{oLLM}, such as \ac{LLaMA} 3.X, \ac{Qwen}, \ac{Phi}, and others, in comparison to previously used closed models on \textit{SemEval 2024 Task 9: BRAINTEASER}. Additionally, the role of \ac{ICL} in enhancing these models' lateral thinking abilities through prompt optimization is examined. Through this analysis, insights into the potential of \acp{oLLM} for tackling lateral thinking tasks are provided.
